{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read\n",
    "import process\n",
    "import numpy as np\n",
    "data, label = read.readData()\n",
    "data = process.normalization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "600/600 [==============================] - 0s 281us/step - loss: 2.2698 - acc: 0.1883\n",
      "Epoch 2/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 2.1781 - acc: 0.3800\n",
      "Epoch 3/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 2.0976 - acc: 0.3967\n",
      "Epoch 4/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 2.0183 - acc: 0.3983\n",
      "Epoch 5/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 1.9407 - acc: 0.4050\n",
      "Epoch 6/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 1.8651 - acc: 0.4083\n",
      "Epoch 7/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 1.7944 - acc: 0.4083\n",
      "Epoch 8/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 1.7286 - acc: 0.4083\n",
      "Epoch 9/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 1.6696 - acc: 0.4117\n",
      "Epoch 10/200\n",
      "600/600 [==============================] - 0s 60us/step - loss: 1.6182 - acc: 0.4117\n",
      "Epoch 11/200\n",
      "600/600 [==============================] - 0s 65us/step - loss: 1.5714 - acc: 0.4133\n",
      "Epoch 12/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 1.5293 - acc: 0.4133\n",
      "Epoch 13/200\n",
      "600/600 [==============================] - 0s 63us/step - loss: 1.4897 - acc: 0.4167\n",
      "Epoch 14/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 1.4528 - acc: 0.4267\n",
      "Epoch 15/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 1.4182 - acc: 0.4483\n",
      "Epoch 16/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 1.3866 - acc: 0.4683\n",
      "Epoch 17/200\n",
      "600/600 [==============================] - 0s 63us/step - loss: 1.3566 - acc: 0.4850\n",
      "Epoch 18/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 1.3287 - acc: 0.5400\n",
      "Epoch 19/200\n",
      "600/600 [==============================] - 0s 65us/step - loss: 1.3022 - acc: 0.5467\n",
      "Epoch 20/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 1.2767 - acc: 0.5567\n",
      "Epoch 21/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 1.2526 - acc: 0.5550\n",
      "Epoch 22/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 1.2294 - acc: 0.5683\n",
      "Epoch 23/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 1.2079 - acc: 0.5633\n",
      "Epoch 24/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 1.1869 - acc: 0.5833\n",
      "Epoch 25/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 1.1668 - acc: 0.5983\n",
      "Epoch 26/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 1.1473 - acc: 0.6133\n",
      "Epoch 27/200\n",
      "600/600 [==============================] - 0s 63us/step - loss: 1.1285 - acc: 0.6133\n",
      "Epoch 28/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 1.1105 - acc: 0.6200\n",
      "Epoch 29/200\n",
      "600/600 [==============================] - 0s 68us/step - loss: 1.0935 - acc: 0.6233\n",
      "Epoch 30/200\n",
      "600/600 [==============================] - 0s 65us/step - loss: 1.0766 - acc: 0.6317\n",
      "Epoch 31/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 1.0610 - acc: 0.6367\n",
      "Epoch 32/200\n",
      "600/600 [==============================] - 0s 67us/step - loss: 1.0465 - acc: 0.6350\n",
      "Epoch 33/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 1.0308 - acc: 0.6367\n",
      "Epoch 34/200\n",
      "600/600 [==============================] - 0s 65us/step - loss: 1.0171 - acc: 0.6267\n",
      "Epoch 35/200\n",
      "600/600 [==============================] - 0s 63us/step - loss: 1.0032 - acc: 0.6467\n",
      "Epoch 36/200\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.9904 - acc: 0.6517\n",
      "Epoch 37/200\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.9777 - acc: 0.6550\n",
      "Epoch 38/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.9654 - acc: 0.6583\n",
      "Epoch 39/200\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.9531 - acc: 0.6633\n",
      "Epoch 40/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.9417 - acc: 0.6683\n",
      "Epoch 41/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.9309 - acc: 0.6633\n",
      "Epoch 42/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.9207 - acc: 0.6800\n",
      "Epoch 43/200\n",
      "600/600 [==============================] - 0s 67us/step - loss: 0.9098 - acc: 0.6833\n",
      "Epoch 44/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.9006 - acc: 0.6817\n",
      "Epoch 45/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.8907 - acc: 0.6967\n",
      "Epoch 46/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.8815 - acc: 0.7117\n",
      "Epoch 47/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.8718 - acc: 0.6933\n",
      "Epoch 48/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.8633 - acc: 0.7200\n",
      "Epoch 49/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.8538 - acc: 0.7383\n",
      "Epoch 50/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.8462 - acc: 0.7450\n",
      "Epoch 51/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.8379 - acc: 0.7400\n",
      "Epoch 52/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.8293 - acc: 0.7450\n",
      "Epoch 53/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.8226 - acc: 0.7450\n",
      "Epoch 54/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.8148 - acc: 0.7450\n",
      "Epoch 55/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.8074 - acc: 0.7550\n",
      "Epoch 56/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.8005 - acc: 0.7467\n",
      "Epoch 57/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.7933 - acc: 0.7583\n",
      "Epoch 58/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.7864 - acc: 0.7617\n",
      "Epoch 59/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.7798 - acc: 0.7567\n",
      "Epoch 60/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.7735 - acc: 0.7567\n",
      "Epoch 61/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.7676 - acc: 0.7683\n",
      "Epoch 62/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.7603 - acc: 0.7617\n",
      "Epoch 63/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.7547 - acc: 0.7683\n",
      "Epoch 64/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.7487 - acc: 0.7550\n",
      "Epoch 65/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.7426 - acc: 0.7583\n",
      "Epoch 66/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.7380 - acc: 0.7650\n",
      "Epoch 67/200\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.7313 - acc: 0.7650\n",
      "Epoch 68/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.7269 - acc: 0.7617\n",
      "Epoch 69/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.7207 - acc: 0.7733\n",
      "Epoch 70/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.7159 - acc: 0.7650\n",
      "Epoch 71/200\n",
      "600/600 [==============================] - 0s 40us/step - loss: 0.7099 - acc: 0.7733\n",
      "Epoch 72/200\n",
      "600/600 [==============================] - 0s 38us/step - loss: 0.7055 - acc: 0.7667\n",
      "Epoch 73/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.7009 - acc: 0.7717\n",
      "Epoch 74/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.6957 - acc: 0.7800\n",
      "Epoch 75/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.6906 - acc: 0.7800\n",
      "Epoch 76/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.6864 - acc: 0.7750\n",
      "Epoch 77/200\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.7354 - acc: 0.781 - 0s 47us/step - loss: 0.6815 - acc: 0.7800\n",
      "Epoch 78/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.6770 - acc: 0.7783\n",
      "Epoch 79/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.6727 - acc: 0.7800\n",
      "Epoch 80/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.6680 - acc: 0.7700\n",
      "Epoch 81/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.6637 - acc: 0.7867\n",
      "Epoch 82/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.6604 - acc: 0.7833\n",
      "Epoch 83/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.6556 - acc: 0.7850\n",
      "Epoch 84/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.6521 - acc: 0.7883\n",
      "Epoch 85/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.6489 - acc: 0.7883\n",
      "Epoch 86/200\n",
      "600/600 [==============================] - 0s 40us/step - loss: 0.6442 - acc: 0.7900\n",
      "Epoch 87/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.6410 - acc: 0.7883\n",
      "Epoch 88/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.6377 - acc: 0.7950\n",
      "Epoch 89/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.6340 - acc: 0.7883\n",
      "Epoch 90/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.6302 - acc: 0.7917\n",
      "Epoch 91/200\n",
      "600/600 [==============================] - 0s 40us/step - loss: 0.6269 - acc: 0.7883\n",
      "Epoch 92/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.6239 - acc: 0.7950\n",
      "Epoch 93/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.6208 - acc: 0.7967\n",
      "Epoch 94/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.6176 - acc: 0.7967\n",
      "Epoch 95/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.6143 - acc: 0.7967\n",
      "Epoch 96/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.6109 - acc: 0.7967\n",
      "Epoch 97/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.6097 - acc: 0.7933\n",
      "Epoch 98/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.6047 - acc: 0.7967\n",
      "Epoch 99/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.6022 - acc: 0.8017\n",
      "Epoch 100/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.5990 - acc: 0.7983\n",
      "Epoch 101/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.5961 - acc: 0.8000\n",
      "Epoch 102/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.5929 - acc: 0.8017\n",
      "Epoch 103/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.5913 - acc: 0.8017\n",
      "Epoch 104/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.5877 - acc: 0.7967\n",
      "Epoch 105/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.5853 - acc: 0.8017\n",
      "Epoch 106/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.5826 - acc: 0.8033\n",
      "Epoch 107/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.5798 - acc: 0.7983\n",
      "Epoch 108/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.5783 - acc: 0.8000\n",
      "Epoch 109/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.5738 - acc: 0.8033\n",
      "Epoch 110/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.5725 - acc: 0.8000\n",
      "Epoch 111/200\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.5702 - acc: 0.8033\n",
      "Epoch 112/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.5683 - acc: 0.7983\n",
      "Epoch 113/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.5646 - acc: 0.8000\n",
      "Epoch 114/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.5635 - acc: 0.8017\n",
      "Epoch 115/200\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.5602 - acc: 0.8000\n",
      "Epoch 116/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.5585 - acc: 0.8100\n",
      "Epoch 117/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.5564 - acc: 0.8017\n",
      "Epoch 118/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.5543 - acc: 0.8150\n",
      "Epoch 119/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.5527 - acc: 0.8067\n",
      "Epoch 120/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.5497 - acc: 0.8067\n",
      "Epoch 121/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.5478 - acc: 0.8083\n",
      "Epoch 122/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.5464 - acc: 0.8167\n",
      "Epoch 123/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.5444 - acc: 0.8167\n",
      "Epoch 124/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.5413 - acc: 0.8067\n",
      "Epoch 125/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.5404 - acc: 0.8133\n",
      "Epoch 126/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.5380 - acc: 0.8133\n",
      "Epoch 127/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.5359 - acc: 0.8150\n",
      "Epoch 128/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.5338 - acc: 0.8200\n",
      "Epoch 129/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.5323 - acc: 0.8133\n",
      "Epoch 130/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.5294 - acc: 0.8200\n",
      "Epoch 131/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.5282 - acc: 0.8217\n",
      "Epoch 132/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.5256 - acc: 0.8150\n",
      "Epoch 133/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.5244 - acc: 0.8150\n",
      "Epoch 134/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.5230 - acc: 0.8283\n",
      "Epoch 135/200\n",
      "600/600 [==============================] - ETA: 0s - loss: 0.4607 - acc: 0.906 - 0s 43us/step - loss: 0.5216 - acc: 0.8233\n",
      "Epoch 136/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.5203 - acc: 0.8217\n",
      "Epoch 137/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.5173 - acc: 0.8267\n",
      "Epoch 138/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.5168 - acc: 0.8300\n",
      "Epoch 139/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.5144 - acc: 0.8300\n",
      "Epoch 140/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.5131 - acc: 0.8267\n",
      "Epoch 141/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.5112 - acc: 0.8267\n",
      "Epoch 142/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.5098 - acc: 0.8283\n",
      "Epoch 143/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.5085 - acc: 0.8283\n",
      "Epoch 144/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.5064 - acc: 0.8283\n",
      "Epoch 145/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.5050 - acc: 0.8317\n",
      "Epoch 146/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.5034 - acc: 0.8333\n",
      "Epoch 147/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.5026 - acc: 0.8250\n",
      "Epoch 148/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4998 - acc: 0.8333\n",
      "Epoch 149/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4988 - acc: 0.8267\n",
      "Epoch 150/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4970 - acc: 0.8283\n",
      "Epoch 151/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.4962 - acc: 0.8350\n",
      "Epoch 152/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4943 - acc: 0.8350\n",
      "Epoch 153/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.4934 - acc: 0.8333\n",
      "Epoch 154/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4912 - acc: 0.8333\n",
      "Epoch 155/200\n",
      "600/600 [==============================] - 0s 38us/step - loss: 0.4901 - acc: 0.8350\n",
      "Epoch 156/200\n",
      "600/600 [==============================] - 0s 40us/step - loss: 0.4893 - acc: 0.8333\n",
      "Epoch 157/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4874 - acc: 0.8333\n",
      "Epoch 158/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.4862 - acc: 0.8383\n",
      "Epoch 159/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4847 - acc: 0.8333\n",
      "Epoch 160/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.4840 - acc: 0.8350\n",
      "Epoch 161/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4821 - acc: 0.8367\n",
      "Epoch 162/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4807 - acc: 0.8333\n",
      "Epoch 163/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.4790 - acc: 0.8333\n",
      "Epoch 164/200\n",
      "600/600 [==============================] - 0s 38us/step - loss: 0.4784 - acc: 0.8383\n",
      "Epoch 165/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.4762 - acc: 0.8333\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 47us/step - loss: 0.4759 - acc: 0.8350\n",
      "Epoch 167/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4749 - acc: 0.8350\n",
      "Epoch 168/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4732 - acc: 0.8400\n",
      "Epoch 169/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4719 - acc: 0.8333\n",
      "Epoch 170/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4715 - acc: 0.8333\n",
      "Epoch 171/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.4692 - acc: 0.8400\n",
      "Epoch 172/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4690 - acc: 0.8350\n",
      "Epoch 173/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.4669 - acc: 0.8383\n",
      "Epoch 174/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.4655 - acc: 0.8367\n",
      "Epoch 175/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.4647 - acc: 0.8317\n",
      "Epoch 176/200\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.4636 - acc: 0.8417\n",
      "Epoch 177/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.4621 - acc: 0.8367\n",
      "Epoch 178/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.4616 - acc: 0.8333\n",
      "Epoch 179/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.4606 - acc: 0.8400\n",
      "Epoch 180/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.4586 - acc: 0.8333\n",
      "Epoch 181/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.4583 - acc: 0.8367\n",
      "Epoch 182/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4567 - acc: 0.8383\n",
      "Epoch 183/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.4563 - acc: 0.8383\n",
      "Epoch 184/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.4537 - acc: 0.8433\n",
      "Epoch 185/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4544 - acc: 0.8367\n",
      "Epoch 186/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4525 - acc: 0.8400\n",
      "Epoch 187/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4510 - acc: 0.8400\n",
      "Epoch 188/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.4504 - acc: 0.8400\n",
      "Epoch 189/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.4486 - acc: 0.8350\n",
      "Epoch 190/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4489 - acc: 0.8350\n",
      "Epoch 191/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.4470 - acc: 0.8367\n",
      "Epoch 192/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.4461 - acc: 0.8367\n",
      "Epoch 193/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.4456 - acc: 0.8383\n",
      "Epoch 194/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4448 - acc: 0.8400\n",
      "Epoch 195/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4430 - acc: 0.8383\n",
      "Epoch 196/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4423 - acc: 0.8367\n",
      "Epoch 197/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4415 - acc: 0.8367\n",
      "Epoch 198/200\n",
      "600/600 [==============================] - 0s 110us/step - loss: 0.4404 - acc: 0.8383\n",
      "Epoch 199/200\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.4389 - acc: 0.8333\n",
      "Epoch 200/200\n",
      "600/600 [==============================] - 0s 77us/step - loss: 0.4384 - acc: 0.8383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3cb85b5f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import keras\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(27,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "label = keras.utils.to_categorical(label, num_classes=10)\n",
    "model.fit(data, label, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.4371 - acc: 0.8400\n",
      "Epoch 2/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.4365 - acc: 0.8417\n",
      "Epoch 3/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4360 - acc: 0.8400\n",
      "Epoch 4/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4343 - acc: 0.8383\n",
      "Epoch 5/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4335 - acc: 0.8350\n",
      "Epoch 6/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.4328 - acc: 0.8367\n",
      "Epoch 7/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.4320 - acc: 0.8367\n",
      "Epoch 8/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4311 - acc: 0.8367\n",
      "Epoch 9/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4295 - acc: 0.8383\n",
      "Epoch 10/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4287 - acc: 0.8383\n",
      "Epoch 11/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.4286 - acc: 0.8367\n",
      "Epoch 12/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.4276 - acc: 0.8333\n",
      "Epoch 13/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4271 - acc: 0.8400\n",
      "Epoch 14/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4263 - acc: 0.8383\n",
      "Epoch 15/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4244 - acc: 0.8350\n",
      "Epoch 16/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4247 - acc: 0.8417\n",
      "Epoch 17/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.4233 - acc: 0.8400\n",
      "Epoch 18/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.4220 - acc: 0.8367\n",
      "Epoch 19/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.4213 - acc: 0.8400\n",
      "Epoch 20/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.4208 - acc: 0.8400\n",
      "Epoch 21/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.4202 - acc: 0.8400\n",
      "Epoch 22/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.4186 - acc: 0.8417\n",
      "Epoch 23/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.4183 - acc: 0.8400\n",
      "Epoch 24/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.4173 - acc: 0.8383\n",
      "Epoch 25/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4163 - acc: 0.8400\n",
      "Epoch 26/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.4167 - acc: 0.8333\n",
      "Epoch 27/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.4152 - acc: 0.8367\n",
      "Epoch 28/200\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.4139 - acc: 0.8417\n",
      "Epoch 29/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.4134 - acc: 0.8417\n",
      "Epoch 30/200\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.4132 - acc: 0.8400\n",
      "Epoch 31/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.4113 - acc: 0.8417\n",
      "Epoch 32/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.4112 - acc: 0.8417\n",
      "Epoch 33/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.4102 - acc: 0.8417\n",
      "Epoch 34/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.4105 - acc: 0.8417\n",
      "Epoch 35/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4085 - acc: 0.8400\n",
      "Epoch 36/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.4078 - acc: 0.8383\n",
      "Epoch 37/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.4079 - acc: 0.8417\n",
      "Epoch 38/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4070 - acc: 0.8450\n",
      "Epoch 39/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4057 - acc: 0.8433\n",
      "Epoch 40/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.4042 - acc: 0.8433\n",
      "Epoch 41/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.4049 - acc: 0.8417\n",
      "Epoch 42/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4035 - acc: 0.8450\n",
      "Epoch 43/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4031 - acc: 0.8433\n",
      "Epoch 44/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.4022 - acc: 0.8417\n",
      "Epoch 45/200\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.4019 - acc: 0.8433\n",
      "Epoch 46/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4004 - acc: 0.8400\n",
      "Epoch 47/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.4003 - acc: 0.8433\n",
      "Epoch 48/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3987 - acc: 0.8467\n",
      "Epoch 49/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3990 - acc: 0.8433\n",
      "Epoch 50/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3985 - acc: 0.8400\n",
      "Epoch 51/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.3975 - acc: 0.8467\n",
      "Epoch 52/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3966 - acc: 0.8450\n",
      "Epoch 53/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3964 - acc: 0.8433\n",
      "Epoch 54/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3944 - acc: 0.8433\n",
      "Epoch 55/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3952 - acc: 0.8400\n",
      "Epoch 56/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3935 - acc: 0.8483\n",
      "Epoch 57/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3928 - acc: 0.8450\n",
      "Epoch 58/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3935 - acc: 0.8467\n",
      "Epoch 59/200\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.3924 - acc: 0.8400\n",
      "Epoch 60/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3910 - acc: 0.8417\n",
      "Epoch 61/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3902 - acc: 0.8483\n",
      "Epoch 62/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3897 - acc: 0.8433\n",
      "Epoch 63/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.3896 - acc: 0.8483\n",
      "Epoch 64/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3889 - acc: 0.8483\n",
      "Epoch 65/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.3878 - acc: 0.8517\n",
      "Epoch 66/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3872 - acc: 0.8450\n",
      "Epoch 67/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3875 - acc: 0.8433\n",
      "Epoch 68/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3866 - acc: 0.8483\n",
      "Epoch 69/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3852 - acc: 0.8500\n",
      "Epoch 70/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3845 - acc: 0.8500\n",
      "Epoch 71/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3846 - acc: 0.8450\n",
      "Epoch 72/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3833 - acc: 0.8483\n",
      "Epoch 73/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3834 - acc: 0.8583\n",
      "Epoch 74/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3821 - acc: 0.8483\n",
      "Epoch 75/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.3821 - acc: 0.8517\n",
      "Epoch 76/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.3817 - acc: 0.8450\n",
      "Epoch 77/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.3802 - acc: 0.8550\n",
      "Epoch 78/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3801 - acc: 0.8517\n",
      "Epoch 79/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3795 - acc: 0.8583\n",
      "Epoch 80/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3789 - acc: 0.8450\n",
      "Epoch 81/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3776 - acc: 0.8517\n",
      "Epoch 82/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3775 - acc: 0.8500\n",
      "Epoch 83/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3765 - acc: 0.8500\n",
      "Epoch 84/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3766 - acc: 0.8550\n",
      "Epoch 85/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3757 - acc: 0.8550\n",
      "Epoch 86/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3746 - acc: 0.8550\n",
      "Epoch 87/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3742 - acc: 0.8550\n",
      "Epoch 88/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3742 - acc: 0.8533\n",
      "Epoch 89/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3734 - acc: 0.8550\n",
      "Epoch 90/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.3728 - acc: 0.8517\n",
      "Epoch 91/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.3727 - acc: 0.8550\n",
      "Epoch 92/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3719 - acc: 0.8617\n",
      "Epoch 93/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3706 - acc: 0.8583\n",
      "Epoch 94/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3710 - acc: 0.8533\n",
      "Epoch 95/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3698 - acc: 0.8483\n",
      "Epoch 96/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3687 - acc: 0.8600\n",
      "Epoch 97/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3686 - acc: 0.8533\n",
      "Epoch 98/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3684 - acc: 0.8617\n",
      "Epoch 99/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.3673 - acc: 0.8567\n",
      "Epoch 100/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.3677 - acc: 0.8550\n",
      "Epoch 101/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.3672 - acc: 0.8583\n",
      "Epoch 102/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3660 - acc: 0.8550\n",
      "Epoch 103/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3660 - acc: 0.8533\n",
      "Epoch 104/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.3654 - acc: 0.8550\n",
      "Epoch 105/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3659 - acc: 0.8617\n",
      "Epoch 106/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3638 - acc: 0.8600\n",
      "Epoch 107/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.3633 - acc: 0.8550\n",
      "Epoch 108/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3639 - acc: 0.8617\n",
      "Epoch 109/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3625 - acc: 0.8550\n",
      "Epoch 110/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3621 - acc: 0.8650\n",
      "Epoch 111/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3611 - acc: 0.8600\n",
      "Epoch 112/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.3614 - acc: 0.8550\n",
      "Epoch 113/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.3607 - acc: 0.8633\n",
      "Epoch 114/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.3604 - acc: 0.8650\n",
      "Epoch 115/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.3594 - acc: 0.8583\n",
      "Epoch 116/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.3590 - acc: 0.8650\n",
      "Epoch 117/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.3591 - acc: 0.8617\n",
      "Epoch 118/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.3577 - acc: 0.8633\n",
      "Epoch 119/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3569 - acc: 0.8583\n",
      "Epoch 120/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.3570 - acc: 0.8683\n",
      "Epoch 121/200\n",
      "600/600 [==============================] - 0s 60us/step - loss: 0.3570 - acc: 0.8617\n",
      "Epoch 122/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.3558 - acc: 0.8633\n",
      "Epoch 123/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3550 - acc: 0.8667\n",
      "Epoch 124/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3553 - acc: 0.8633\n",
      "Epoch 125/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3550 - acc: 0.8633\n",
      "Epoch 126/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3539 - acc: 0.8600\n",
      "Epoch 127/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3538 - acc: 0.8683\n",
      "Epoch 128/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.3533 - acc: 0.8667\n",
      "Epoch 129/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3520 - acc: 0.8700\n",
      "Epoch 130/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3524 - acc: 0.8667\n",
      "Epoch 131/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3509 - acc: 0.8683\n",
      "Epoch 132/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3515 - acc: 0.8617\n",
      "Epoch 133/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3505 - acc: 0.8717\n",
      "Epoch 134/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.3502 - acc: 0.8700\n",
      "Epoch 135/200\n",
      "600/600 [==============================] - 0s 40us/step - loss: 0.3485 - acc: 0.8700\n",
      "Epoch 136/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3490 - acc: 0.8683\n",
      "Epoch 137/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3490 - acc: 0.8683\n",
      "Epoch 138/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3476 - acc: 0.8700\n",
      "Epoch 139/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3480 - acc: 0.8650\n",
      "Epoch 140/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3467 - acc: 0.8683\n",
      "Epoch 141/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3465 - acc: 0.8700\n",
      "Epoch 142/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3476 - acc: 0.8717\n",
      "Epoch 143/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3446 - acc: 0.8750\n",
      "Epoch 144/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3457 - acc: 0.8633\n",
      "Epoch 145/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.3444 - acc: 0.8717\n",
      "Epoch 146/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3432 - acc: 0.8667\n",
      "Epoch 147/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3441 - acc: 0.8717\n",
      "Epoch 148/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3429 - acc: 0.8767\n",
      "Epoch 149/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3419 - acc: 0.8717\n",
      "Epoch 150/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3425 - acc: 0.8683\n",
      "Epoch 151/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3418 - acc: 0.8717\n",
      "Epoch 152/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3414 - acc: 0.8717\n",
      "Epoch 153/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3413 - acc: 0.8700\n",
      "Epoch 154/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.3406 - acc: 0.8750\n",
      "Epoch 155/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.3398 - acc: 0.8700\n",
      "Epoch 156/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3394 - acc: 0.8700\n",
      "Epoch 157/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3392 - acc: 0.8733\n",
      "Epoch 158/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3385 - acc: 0.8700\n",
      "Epoch 159/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3379 - acc: 0.8700\n",
      "Epoch 160/200\n",
      "600/600 [==============================] - 0s 50us/step - loss: 0.3378 - acc: 0.8750\n",
      "Epoch 161/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3376 - acc: 0.8733\n",
      "Epoch 162/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.3368 - acc: 0.8733\n",
      "Epoch 163/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.3359 - acc: 0.8767\n",
      "Epoch 164/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.3357 - acc: 0.8717\n",
      "Epoch 165/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.3351 - acc: 0.8733\n",
      "Epoch 166/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3354 - acc: 0.8733\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 42us/step - loss: 0.3346 - acc: 0.8783\n",
      "Epoch 168/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3332 - acc: 0.8733\n",
      "Epoch 169/200\n",
      "600/600 [==============================] - 0s 38us/step - loss: 0.3335 - acc: 0.8750\n",
      "Epoch 170/200\n",
      "600/600 [==============================] - 0s 42us/step - loss: 0.3330 - acc: 0.8767\n",
      "Epoch 171/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3325 - acc: 0.8750\n",
      "Epoch 172/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3315 - acc: 0.8733\n",
      "Epoch 173/200\n",
      "600/600 [==============================] - 0s 47us/step - loss: 0.3313 - acc: 0.8733\n",
      "Epoch 174/200\n",
      "600/600 [==============================] - 0s 43us/step - loss: 0.3320 - acc: 0.8750\n",
      "Epoch 175/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.3307 - acc: 0.8733\n",
      "Epoch 176/200\n",
      "600/600 [==============================] - 0s 45us/step - loss: 0.3300 - acc: 0.8717\n",
      "Epoch 177/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3294 - acc: 0.8750\n",
      "Epoch 178/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3294 - acc: 0.8683\n",
      "Epoch 179/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.3288 - acc: 0.8717\n",
      "Epoch 180/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.3287 - acc: 0.8750\n",
      "Epoch 181/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.3277 - acc: 0.8767\n",
      "Epoch 182/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.3288 - acc: 0.8733\n",
      "Epoch 183/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.3270 - acc: 0.8767\n",
      "Epoch 184/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.3263 - acc: 0.8733\n",
      "Epoch 185/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3255 - acc: 0.8733\n",
      "Epoch 186/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3266 - acc: 0.8800\n",
      "Epoch 187/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3250 - acc: 0.8750\n",
      "Epoch 188/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3245 - acc: 0.8733\n",
      "Epoch 189/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3242 - acc: 0.8733\n",
      "Epoch 190/200\n",
      "600/600 [==============================] - 0s 55us/step - loss: 0.3245 - acc: 0.8817\n",
      "Epoch 191/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.3243 - acc: 0.8717\n",
      "Epoch 192/200\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.3237 - acc: 0.8767\n",
      "Epoch 193/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3227 - acc: 0.8767\n",
      "Epoch 194/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3223 - acc: 0.8767\n",
      "Epoch 195/200\n",
      "600/600 [==============================] - 0s 53us/step - loss: 0.3215 - acc: 0.8750\n",
      "Epoch 196/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.3227 - acc: 0.8767\n",
      "Epoch 197/200\n",
      "600/600 [==============================] - 0s 48us/step - loss: 0.3216 - acc: 0.8717\n",
      "Epoch 198/200\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.3215 - acc: 0.8750\n",
      "Epoch 199/200\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.3206 - acc: 0.8783\n",
      "Epoch 200/200\n",
      "600/600 [==============================] - 0s 52us/step - loss: 0.3202 - acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3d2a2f7f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, label, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2399084e-03 1.2634842e-02 6.1828442e-02 5.9120025e-02 2.5799184e-04\n",
      " 5.9730530e-05 1.4247732e-01 7.1764742e-03 8.7904895e-04 7.1432620e-01]\n"
     ]
    }
   ],
   "source": [
    "print(result[599])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = generate.generateConfusionMatrix(result, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 29, 0, 0, 0, 0, 0, 0, 0], [0, 40, 0, 0, 3, 0, 0, 3, 0, 2], [0, 0, 194, 0, 0, 0, 0, 0, 9, 4], [0, 0, 0, 45, 0, 0, 0, 0, 0, 1], [0, 6, 0, 0, 33, 0, 0, 3, 0, 0], [0, 0, 0, 0, 0, 9, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 69, 0, 0, 0], [0, 12, 0, 0, 3, 0, 0, 21, 0, 1], [0, 0, 17, 0, 0, 0, 0, 0, 50, 0], [0, 0, 1, 1, 0, 0, 1, 0, 0, 41]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-788ecc1b8be7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(data, label, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420 samples, validate on 180 samples\n",
      "Epoch 1/50\n",
      "420/420 [==============================] - 0s 640us/step - loss: 2.1389 - acc: 0.4619 - val_loss: 2.4056 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "420/420 [==============================] - 0s 152us/step - loss: 1.8736 - acc: 0.5000 - val_loss: 2.5533 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "420/420 [==============================] - 0s 141us/step - loss: 1.6030 - acc: 0.5024 - val_loss: 2.7691 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "420/420 [==============================] - 0s 126us/step - loss: 1.3844 - acc: 0.5238 - val_loss: 3.0559 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "420/420 [==============================] - 0s 122us/step - loss: 1.2390 - acc: 0.5929 - val_loss: 3.3358 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 1.1319 - acc: 0.6333 - val_loss: 3.6553 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "420/420 [==============================] - 0s 129us/step - loss: 1.0488 - acc: 0.6262 - val_loss: 3.9394 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.9816 - acc: 0.6190 - val_loss: 4.2179 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.9264 - acc: 0.6643 - val_loss: 4.5244 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.8787 - acc: 0.6524 - val_loss: 4.8282 - val_acc: 0.0056\n",
      "Epoch 11/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.8369 - acc: 0.6929 - val_loss: 5.1442 - val_acc: 0.0056\n",
      "Epoch 12/50\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.8013 - acc: 0.7071 - val_loss: 5.4591 - val_acc: 0.0389\n",
      "Epoch 13/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.7681 - acc: 0.7214 - val_loss: 5.7718 - val_acc: 0.0500\n",
      "Epoch 14/50\n",
      "420/420 [==============================] - 0s 112us/step - loss: 0.7380 - acc: 0.7381 - val_loss: 6.1208 - val_acc: 0.1444\n",
      "Epoch 15/50\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.7115 - acc: 0.7762 - val_loss: 6.4286 - val_acc: 0.1556\n",
      "Epoch 16/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.6876 - acc: 0.7905 - val_loss: 6.7841 - val_acc: 0.1611\n",
      "Epoch 17/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.6652 - acc: 0.7881 - val_loss: 7.1249 - val_acc: 0.1611\n",
      "Epoch 18/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.6437 - acc: 0.7976 - val_loss: 7.4468 - val_acc: 0.1611\n",
      "Epoch 19/50\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.6240 - acc: 0.8024 - val_loss: 7.7737 - val_acc: 0.1611\n",
      "Epoch 20/50\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.6053 - acc: 0.8214 - val_loss: 8.1279 - val_acc: 0.1611\n",
      "Epoch 21/50\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.5882 - acc: 0.8214 - val_loss: 8.4473 - val_acc: 0.1611\n",
      "Epoch 22/50\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.5718 - acc: 0.8381 - val_loss: 8.7516 - val_acc: 0.1611\n",
      "Epoch 23/50\n",
      "420/420 [==============================] - 0s 129us/step - loss: 0.5571 - acc: 0.8310 - val_loss: 9.0580 - val_acc: 0.1611\n",
      "Epoch 24/50\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.5435 - acc: 0.8357 - val_loss: 9.3542 - val_acc: 0.1611\n",
      "Epoch 25/50\n",
      "420/420 [==============================] - 0s 150us/step - loss: 0.5299 - acc: 0.8452 - val_loss: 9.6502 - val_acc: 0.1611\n",
      "Epoch 26/50\n",
      "420/420 [==============================] - 0s 129us/step - loss: 0.5182 - acc: 0.8429 - val_loss: 9.9029 - val_acc: 0.1667\n",
      "Epoch 27/50\n",
      "420/420 [==============================] - 0s 141us/step - loss: 0.5078 - acc: 0.8548 - val_loss: 10.1680 - val_acc: 0.1667\n",
      "Epoch 28/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.4967 - acc: 0.8476 - val_loss: 10.4052 - val_acc: 0.1778\n",
      "Epoch 29/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.4859 - acc: 0.8714 - val_loss: 10.6289 - val_acc: 0.1778\n",
      "Epoch 30/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.4768 - acc: 0.8667 - val_loss: 10.8484 - val_acc: 0.1778\n",
      "Epoch 31/50\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.4674 - acc: 0.8810 - val_loss: 11.0734 - val_acc: 0.1778\n",
      "Epoch 32/50\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.4588 - acc: 0.8714 - val_loss: 11.2622 - val_acc: 0.1778\n",
      "Epoch 33/50\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.4507 - acc: 0.8833 - val_loss: 11.4635 - val_acc: 0.1778\n",
      "Epoch 34/50\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.4431 - acc: 0.8905 - val_loss: 11.6480 - val_acc: 0.1778\n",
      "Epoch 35/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.4359 - acc: 0.8810 - val_loss: 11.7814 - val_acc: 0.1778\n",
      "Epoch 36/50\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.4290 - acc: 0.8833 - val_loss: 11.9301 - val_acc: 0.1778\n",
      "Epoch 37/50\n",
      "420/420 [==============================] - 0s 155us/step - loss: 0.4219 - acc: 0.8905 - val_loss: 12.0916 - val_acc: 0.1778\n",
      "Epoch 38/50\n",
      "420/420 [==============================] - 0s 155us/step - loss: 0.4165 - acc: 0.8881 - val_loss: 12.1852 - val_acc: 0.1778\n",
      "Epoch 39/50\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.4099 - acc: 0.8881 - val_loss: 12.2766 - val_acc: 0.1778\n",
      "Epoch 40/50\n",
      "420/420 [==============================] - 0s 176us/step - loss: 0.4036 - acc: 0.8833 - val_loss: 12.3475 - val_acc: 0.1778\n",
      "Epoch 41/50\n",
      "420/420 [==============================] - 0s 186us/step - loss: 0.3991 - acc: 0.8857 - val_loss: 12.3994 - val_acc: 0.1778\n",
      "Epoch 42/50\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.3936 - acc: 0.8857 - val_loss: 12.4452 - val_acc: 0.1778\n",
      "Epoch 43/50\n",
      "420/420 [==============================] - 0s 188us/step - loss: 0.3894 - acc: 0.8905 - val_loss: 12.4803 - val_acc: 0.1778\n",
      "Epoch 44/50\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.3839 - acc: 0.8881 - val_loss: 12.5223 - val_acc: 0.1778\n",
      "Epoch 45/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.3798 - acc: 0.8905 - val_loss: 12.5546 - val_acc: 0.1778\n",
      "Epoch 46/50\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.3742 - acc: 0.8905 - val_loss: 12.5953 - val_acc: 0.1778\n",
      "Epoch 47/50\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.3703 - acc: 0.8857 - val_loss: 12.6163 - val_acc: 0.1778\n",
      "Epoch 48/50\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.3651 - acc: 0.8905 - val_loss: 12.6374 - val_acc: 0.1778\n",
      "Epoch 49/50\n",
      "420/420 [==============================] - 0s 172us/step - loss: 0.3614 - acc: 0.8857 - val_loss: 12.6704 - val_acc: 0.1778\n",
      "Epoch 50/50\n",
      "420/420 [==============================] - 0s 200us/step - loss: 0.3583 - acc: 0.8881 - val_loss: 12.6859 - val_acc: 0.1778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3d2994b38>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(32, input_shape=(27,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model2.fit(data, label, validation_split=0.3, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420 samples, validate on 180 samples\n",
      "Epoch 1/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.3546 - acc: 0.8881 - val_loss: 12.7039 - val_acc: 0.1778\n",
      "Epoch 2/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.3510 - acc: 0.8881 - val_loss: 12.7326 - val_acc: 0.1778\n",
      "Epoch 3/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.3475 - acc: 0.8857 - val_loss: 12.7487 - val_acc: 0.1778\n",
      "Epoch 4/50\n",
      "420/420 [==============================] - 0s 114us/step - loss: 0.3440 - acc: 0.8881 - val_loss: 12.7672 - val_acc: 0.1778\n",
      "Epoch 5/50\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.3419 - acc: 0.8881 - val_loss: 12.7722 - val_acc: 0.1778\n",
      "Epoch 6/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.3368 - acc: 0.8929 - val_loss: 12.8012 - val_acc: 0.1778\n",
      "Epoch 7/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.3356 - acc: 0.8881 - val_loss: 12.8016 - val_acc: 0.1778\n",
      "Epoch 8/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.3330 - acc: 0.8881 - val_loss: 12.8138 - val_acc: 0.1778\n",
      "Epoch 9/50\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.3286 - acc: 0.8881 - val_loss: 12.8333 - val_acc: 0.1778\n",
      "Epoch 10/50\n",
      "420/420 [==============================] - 0s 121us/step - loss: 0.3252 - acc: 0.8881 - val_loss: 12.8583 - val_acc: 0.1778\n",
      "Epoch 11/50\n",
      "420/420 [==============================] - 0s 148us/step - loss: 0.3243 - acc: 0.8905 - val_loss: 12.8643 - val_acc: 0.1778\n",
      "Epoch 12/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.3205 - acc: 0.8952 - val_loss: 12.8740 - val_acc: 0.1778\n",
      "Epoch 13/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.3169 - acc: 0.8881 - val_loss: 12.8795 - val_acc: 0.1778\n",
      "Epoch 14/50\n",
      "420/420 [==============================] - 0s 155us/step - loss: 0.3167 - acc: 0.8881 - val_loss: 12.8731 - val_acc: 0.1778\n",
      "Epoch 15/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.3133 - acc: 0.8952 - val_loss: 12.8924 - val_acc: 0.1778\n",
      "Epoch 16/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.3110 - acc: 0.8905 - val_loss: 12.8991 - val_acc: 0.1778\n",
      "Epoch 17/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.3083 - acc: 0.8929 - val_loss: 12.9067 - val_acc: 0.1778\n",
      "Epoch 18/50\n",
      "420/420 [==============================] - 0s 200us/step - loss: 0.3061 - acc: 0.8905 - val_loss: 12.9173 - val_acc: 0.1778\n",
      "Epoch 19/50\n",
      "420/420 [==============================] - 0s 145us/step - loss: 0.3036 - acc: 0.8881 - val_loss: 12.9252 - val_acc: 0.1778\n",
      "Epoch 20/50\n",
      "420/420 [==============================] - 0s 172us/step - loss: 0.3011 - acc: 0.8976 - val_loss: 12.9415 - val_acc: 0.1778\n",
      "Epoch 21/50\n",
      "420/420 [==============================] - 0s 219us/step - loss: 0.2995 - acc: 0.8905 - val_loss: 12.9473 - val_acc: 0.1778\n",
      "Epoch 22/50\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.2975 - acc: 0.8976 - val_loss: 12.9526 - val_acc: 0.1778\n",
      "Epoch 23/50\n",
      "420/420 [==============================] - 0s 167us/step - loss: 0.2944 - acc: 0.8881 - val_loss: 12.9627 - val_acc: 0.1778\n",
      "Epoch 24/50\n",
      "420/420 [==============================] - 0s 195us/step - loss: 0.2942 - acc: 0.8881 - val_loss: 12.9693 - val_acc: 0.1778\n",
      "Epoch 25/50\n",
      "420/420 [==============================] - 0s 195us/step - loss: 0.2915 - acc: 0.8952 - val_loss: 12.9729 - val_acc: 0.1778\n",
      "Epoch 26/50\n",
      "420/420 [==============================] - 0s 186us/step - loss: 0.2890 - acc: 0.8905 - val_loss: 12.9812 - val_acc: 0.1778\n",
      "Epoch 27/50\n",
      "420/420 [==============================] - 0s 188us/step - loss: 0.2870 - acc: 0.8976 - val_loss: 12.9804 - val_acc: 0.1778\n",
      "Epoch 28/50\n",
      "420/420 [==============================] - 0s 186us/step - loss: 0.2850 - acc: 0.8881 - val_loss: 12.9776 - val_acc: 0.1778\n",
      "Epoch 29/50\n",
      "420/420 [==============================] - 0s 176us/step - loss: 0.2847 - acc: 0.8952 - val_loss: 12.9811 - val_acc: 0.1778\n",
      "Epoch 30/50\n",
      "420/420 [==============================] - 0s 181us/step - loss: 0.2823 - acc: 0.8929 - val_loss: 12.9837 - val_acc: 0.1778\n",
      "Epoch 31/50\n",
      "420/420 [==============================] - 0s 181us/step - loss: 0.2810 - acc: 0.8976 - val_loss: 12.9922 - val_acc: 0.1778\n",
      "Epoch 32/50\n",
      "420/420 [==============================] - 0s 193us/step - loss: 0.2794 - acc: 0.8929 - val_loss: 12.9957 - val_acc: 0.1778\n",
      "Epoch 33/50\n",
      "420/420 [==============================] - 0s 176us/step - loss: 0.2787 - acc: 0.8952 - val_loss: 13.0056 - val_acc: 0.1778\n",
      "Epoch 34/50\n",
      "420/420 [==============================] - 0s 193us/step - loss: 0.2768 - acc: 0.8952 - val_loss: 13.0031 - val_acc: 0.1778\n",
      "Epoch 35/50\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.2740 - acc: 0.8952 - val_loss: 13.0016 - val_acc: 0.1778\n",
      "Epoch 36/50\n",
      "420/420 [==============================] - 0s 141us/step - loss: 0.2728 - acc: 0.8976 - val_loss: 13.0097 - val_acc: 0.1778\n",
      "Epoch 37/50\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.2712 - acc: 0.8976 - val_loss: 13.0139 - val_acc: 0.1778\n",
      "Epoch 38/50\n",
      "420/420 [==============================] - 0s 167us/step - loss: 0.2701 - acc: 0.8952 - val_loss: 13.0177 - val_acc: 0.1778\n",
      "Epoch 39/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.2685 - acc: 0.8905 - val_loss: 13.0163 - val_acc: 0.1778\n",
      "Epoch 40/50\n",
      "420/420 [==============================] - 0s 195us/step - loss: 0.2669 - acc: 0.8952 - val_loss: 13.0234 - val_acc: 0.1778\n",
      "Epoch 41/50\n",
      "420/420 [==============================] - 0s 195us/step - loss: 0.2653 - acc: 0.8952 - val_loss: 13.0204 - val_acc: 0.1778\n",
      "Epoch 42/50\n",
      "420/420 [==============================] - 0s 181us/step - loss: 0.2644 - acc: 0.8952 - val_loss: 13.0249 - val_acc: 0.1778\n",
      "Epoch 43/50\n",
      "420/420 [==============================] - 0s 183us/step - loss: 0.2638 - acc: 0.8952 - val_loss: 13.0305 - val_acc: 0.1778\n",
      "Epoch 44/50\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.2619 - acc: 0.8929 - val_loss: 13.0339 - val_acc: 0.1778\n",
      "Epoch 45/50\n",
      "420/420 [==============================] - 0s 167us/step - loss: 0.2609 - acc: 0.8952 - val_loss: 13.0301 - val_acc: 0.1778\n",
      "Epoch 46/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.2575 - acc: 0.8976 - val_loss: 13.0468 - val_acc: 0.1778\n",
      "Epoch 47/50\n",
      "420/420 [==============================] - 0s 113us/step - loss: 0.2596 - acc: 0.8952 - val_loss: 13.0377 - val_acc: 0.1778\n",
      "Epoch 48/50\n",
      "420/420 [==============================] - 0s 172us/step - loss: 0.2572 - acc: 0.8952 - val_loss: 13.0328 - val_acc: 0.1778\n",
      "Epoch 49/50\n",
      "420/420 [==============================] - 0s 198us/step - loss: 0.2557 - acc: 0.8929 - val_loss: 13.0318 - val_acc: 0.1778\n",
      "Epoch 50/50\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.2544 - acc: 0.8976 - val_loss: 13.0359 - val_acc: 0.1778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3d2a2f828>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(data, label, validation_split=0.3, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420 samples, validate on 180 samples\n",
      "Epoch 1/50\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.2528 - acc: 0.8952 - val_loss: 13.0285 - val_acc: 0.1778\n",
      "Epoch 2/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.2508 - acc: 0.8952 - val_loss: 13.0434 - val_acc: 0.1778\n",
      "Epoch 3/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.2513 - acc: 0.8857 - val_loss: 13.0441 - val_acc: 0.1778\n",
      "Epoch 4/50\n",
      "420/420 [==============================] - 0s 112us/step - loss: 0.2498 - acc: 0.8976 - val_loss: 13.0428 - val_acc: 0.1778\n",
      "Epoch 5/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.2491 - acc: 0.8929 - val_loss: 13.0436 - val_acc: 0.1778\n",
      "Epoch 6/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.2473 - acc: 0.8952 - val_loss: 13.0402 - val_acc: 0.1778\n",
      "Epoch 7/50\n",
      "420/420 [==============================] - 0s 129us/step - loss: 0.2469 - acc: 0.8881 - val_loss: 13.0455 - val_acc: 0.1778\n",
      "Epoch 8/50\n",
      "420/420 [==============================] - 0s 124us/step - loss: 0.2463 - acc: 0.8905 - val_loss: 13.0430 - val_acc: 0.1778\n",
      "Epoch 9/50\n",
      "420/420 [==============================] - 0s 124us/step - loss: 0.2438 - acc: 0.8929 - val_loss: 13.0385 - val_acc: 0.1778\n",
      "Epoch 10/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.2436 - acc: 0.8929 - val_loss: 13.0381 - val_acc: 0.1778\n",
      "Epoch 11/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.2420 - acc: 0.8952 - val_loss: 13.0408 - val_acc: 0.1778\n",
      "Epoch 12/50\n",
      "420/420 [==============================] - 0s 114us/step - loss: 0.2422 - acc: 0.9000 - val_loss: 13.0434 - val_acc: 0.1778\n",
      "Epoch 13/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.2416 - acc: 0.9000 - val_loss: 13.0423 - val_acc: 0.1778\n",
      "Epoch 14/50\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.2393 - acc: 0.8952 - val_loss: 13.0495 - val_acc: 0.1778\n",
      "Epoch 15/50\n",
      "420/420 [==============================] - 0s 181us/step - loss: 0.2398 - acc: 0.8976 - val_loss: 13.0417 - val_acc: 0.1778\n",
      "Epoch 16/50\n",
      "420/420 [==============================] - 0s 172us/step - loss: 0.2374 - acc: 0.8952 - val_loss: 13.0415 - val_acc: 0.1778\n",
      "Epoch 17/50\n",
      "420/420 [==============================] - 0s 179us/step - loss: 0.2358 - acc: 0.8929 - val_loss: 13.0376 - val_acc: 0.1778\n",
      "Epoch 18/50\n",
      "420/420 [==============================] - 0s 150us/step - loss: 0.2363 - acc: 0.8929 - val_loss: 13.0426 - val_acc: 0.1778\n",
      "Epoch 19/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.2363 - acc: 0.8929 - val_loss: 13.0448 - val_acc: 0.1778\n",
      "Epoch 20/50\n",
      "420/420 [==============================] - 0s 155us/step - loss: 0.2336 - acc: 0.8952 - val_loss: 13.0534 - val_acc: 0.1778\n",
      "Epoch 21/50\n",
      "420/420 [==============================] - 0s 148us/step - loss: 0.2339 - acc: 0.8929 - val_loss: 13.0429 - val_acc: 0.1778\n",
      "Epoch 22/50\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.2325 - acc: 0.8976 - val_loss: 13.0444 - val_acc: 0.1778\n",
      "Epoch 23/50\n",
      "420/420 [==============================] - 0s 181us/step - loss: 0.2315 - acc: 0.9000 - val_loss: 13.0402 - val_acc: 0.1778\n",
      "Epoch 24/50\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.2298 - acc: 0.8905 - val_loss: 13.0466 - val_acc: 0.1778\n",
      "Epoch 25/50\n",
      "420/420 [==============================] - 0s 174us/step - loss: 0.2283 - acc: 0.8857 - val_loss: 13.0476 - val_acc: 0.1778\n",
      "Epoch 26/50\n",
      "420/420 [==============================] - 0s 181us/step - loss: 0.2291 - acc: 0.8952 - val_loss: 13.0489 - val_acc: 0.1778\n",
      "Epoch 27/50\n",
      "420/420 [==============================] - 0s 174us/step - loss: 0.2279 - acc: 0.8929 - val_loss: 13.0390 - val_acc: 0.1778\n",
      "Epoch 28/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.2264 - acc: 0.8929 - val_loss: 13.0523 - val_acc: 0.1778\n",
      "Epoch 29/50\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.2258 - acc: 0.9024 - val_loss: 13.0406 - val_acc: 0.1778\n",
      "Epoch 30/50\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.2258 - acc: 0.8976 - val_loss: 13.0346 - val_acc: 0.1778\n",
      "Epoch 31/50\n",
      "420/420 [==============================] - 0s 179us/step - loss: 0.2248 - acc: 0.8929 - val_loss: 13.0343 - val_acc: 0.1778\n",
      "Epoch 32/50\n",
      "420/420 [==============================] - 0s 179us/step - loss: 0.2240 - acc: 0.8976 - val_loss: 13.0343 - val_acc: 0.1778\n",
      "Epoch 33/50\n",
      "420/420 [==============================] - 0s 193us/step - loss: 0.2229 - acc: 0.8976 - val_loss: 13.0309 - val_acc: 0.1778\n",
      "Epoch 34/50\n",
      "420/420 [==============================] - 0s 179us/step - loss: 0.2224 - acc: 0.9024 - val_loss: 13.0389 - val_acc: 0.1778\n",
      "Epoch 35/50\n",
      "420/420 [==============================] - 0s 186us/step - loss: 0.2218 - acc: 0.8976 - val_loss: 13.0257 - val_acc: 0.1778\n",
      "Epoch 36/50\n",
      "420/420 [==============================] - 0s 162us/step - loss: 0.2205 - acc: 0.9000 - val_loss: 13.0278 - val_acc: 0.1778\n",
      "Epoch 37/50\n",
      "420/420 [==============================] - 0s 174us/step - loss: 0.2195 - acc: 0.9000 - val_loss: 13.0275 - val_acc: 0.1778\n",
      "Epoch 38/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.2189 - acc: 0.9000 - val_loss: 13.0332 - val_acc: 0.1778\n",
      "Epoch 39/50\n",
      "420/420 [==============================] - 0s 117us/step - loss: 0.2185 - acc: 0.8976 - val_loss: 13.0218 - val_acc: 0.1778\n",
      "Epoch 40/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.2180 - acc: 0.9000 - val_loss: 13.0198 - val_acc: 0.1778\n",
      "Epoch 41/50\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.2168 - acc: 0.9048 - val_loss: 13.0176 - val_acc: 0.1778\n",
      "Epoch 42/50\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.2156 - acc: 0.9048 - val_loss: 13.0288 - val_acc: 0.1778\n",
      "Epoch 43/50\n",
      "420/420 [==============================] - 0s 179us/step - loss: 0.2152 - acc: 0.8952 - val_loss: 13.0242 - val_acc: 0.1778\n",
      "Epoch 44/50\n",
      "420/420 [==============================] - 0s 179us/step - loss: 0.2146 - acc: 0.9000 - val_loss: 13.0277 - val_acc: 0.1778\n",
      "Epoch 45/50\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.2142 - acc: 0.9024 - val_loss: 13.0286 - val_acc: 0.1778\n",
      "Epoch 46/50\n",
      "420/420 [==============================] - 0s 150us/step - loss: 0.2124 - acc: 0.9024 - val_loss: 13.0287 - val_acc: 0.1778\n",
      "Epoch 47/50\n",
      "420/420 [==============================] - 0s 145us/step - loss: 0.2130 - acc: 0.9024 - val_loss: 13.0253 - val_acc: 0.1778\n",
      "Epoch 48/50\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.2107 - acc: 0.9024 - val_loss: 13.0264 - val_acc: 0.1778\n",
      "Epoch 49/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.2125 - acc: 0.9071 - val_loss: 13.0249 - val_acc: 0.1778\n",
      "Epoch 50/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.2100 - acc: 0.9024 - val_loss: 13.0251 - val_acc: 0.1778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3d2a2f940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(data, label, validation_split=0.3, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420 samples, validate on 180 samples\n",
      "Epoch 1/50\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.2096 - acc: 0.9024 - val_loss: 13.0180 - val_acc: 0.1778\n",
      "Epoch 2/50\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.2097 - acc: 0.9095 - val_loss: 13.0239 - val_acc: 0.1778\n",
      "Epoch 3/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.2095 - acc: 0.9071 - val_loss: 13.0196 - val_acc: 0.1778\n",
      "Epoch 4/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.2075 - acc: 0.9071 - val_loss: 13.0239 - val_acc: 0.1778\n",
      "Epoch 5/50\n",
      "420/420 [==============================] - 0s 131us/step - loss: 0.2061 - acc: 0.9095 - val_loss: 13.0294 - val_acc: 0.1778\n",
      "Epoch 6/50\n",
      "420/420 [==============================] - 0s 129us/step - loss: 0.2068 - acc: 0.9143 - val_loss: 13.0240 - val_acc: 0.1778\n",
      "Epoch 7/50\n",
      "420/420 [==============================] - 0s 129us/step - loss: 0.2059 - acc: 0.9071 - val_loss: 13.0155 - val_acc: 0.1778\n",
      "Epoch 8/50\n",
      "420/420 [==============================] - 0s 126us/step - loss: 0.2046 - acc: 0.9048 - val_loss: 13.0126 - val_acc: 0.1778\n",
      "Epoch 9/50\n",
      "420/420 [==============================] - 0s 124us/step - loss: 0.2042 - acc: 0.9143 - val_loss: 13.0244 - val_acc: 0.1778\n",
      "Epoch 10/50\n",
      "420/420 [==============================] - 0s 145us/step - loss: 0.2042 - acc: 0.9095 - val_loss: 13.0160 - val_acc: 0.1778\n",
      "Epoch 11/50\n",
      "420/420 [==============================] - 0s 133us/step - loss: 0.2029 - acc: 0.9071 - val_loss: 13.0204 - val_acc: 0.1778\n",
      "Epoch 12/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.2027 - acc: 0.9143 - val_loss: 13.0140 - val_acc: 0.1778\n",
      "Epoch 13/50\n",
      "420/420 [==============================] - 0s 128us/step - loss: 0.2025 - acc: 0.9167 - val_loss: 13.0230 - val_acc: 0.1778\n",
      "Epoch 14/50\n",
      "420/420 [==============================] - 0s 172us/step - loss: 0.2019 - acc: 0.9095 - val_loss: 13.0200 - val_acc: 0.1778\n",
      "Epoch 15/50\n",
      "420/420 [==============================] - 0s 193us/step - loss: 0.2001 - acc: 0.9143 - val_loss: 13.0177 - val_acc: 0.1778\n",
      "Epoch 16/50\n",
      "420/420 [==============================] - 0s 179us/step - loss: 0.2005 - acc: 0.9119 - val_loss: 13.0250 - val_acc: 0.1778\n",
      "Epoch 17/50\n",
      "420/420 [==============================] - 0s 181us/step - loss: 0.1996 - acc: 0.9143 - val_loss: 13.0184 - val_acc: 0.1778\n",
      "Epoch 18/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.1994 - acc: 0.9167 - val_loss: 13.0210 - val_acc: 0.1778\n",
      "Epoch 19/50\n",
      "420/420 [==============================] - 0s 150us/step - loss: 0.1984 - acc: 0.9214 - val_loss: 13.0218 - val_acc: 0.1778\n",
      "Epoch 20/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.1973 - acc: 0.9190 - val_loss: 13.0256 - val_acc: 0.1778\n",
      "Epoch 21/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.1970 - acc: 0.9190 - val_loss: 13.0178 - val_acc: 0.1778\n",
      "Epoch 22/50\n",
      "420/420 [==============================] - 0s 164us/step - loss: 0.1967 - acc: 0.9214 - val_loss: 13.0171 - val_acc: 0.1778\n",
      "Epoch 23/50\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.1959 - acc: 0.9143 - val_loss: 13.0216 - val_acc: 0.1778\n",
      "Epoch 24/50\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.1937 - acc: 0.9262 - val_loss: 13.0324 - val_acc: 0.1778\n",
      "Epoch 25/50\n",
      "420/420 [==============================] - 0s 181us/step - loss: 0.1951 - acc: 0.9238 - val_loss: 13.0217 - val_acc: 0.1778\n",
      "Epoch 26/50\n",
      "420/420 [==============================] - 0s 129us/step - loss: 0.1947 - acc: 0.9214 - val_loss: 13.0111 - val_acc: 0.1778\n",
      "Epoch 27/50\n",
      "420/420 [==============================] - 0s 124us/step - loss: 0.1933 - acc: 0.9190 - val_loss: 13.0189 - val_acc: 0.1778\n",
      "Epoch 28/50\n",
      "420/420 [==============================] - 0s 167us/step - loss: 0.1932 - acc: 0.9214 - val_loss: 13.0168 - val_acc: 0.1778\n",
      "Epoch 29/50\n",
      "420/420 [==============================] - 0s 198us/step - loss: 0.1922 - acc: 0.9238 - val_loss: 13.0071 - val_acc: 0.1778\n",
      "Epoch 30/50\n",
      "420/420 [==============================] - 0s 186us/step - loss: 0.1918 - acc: 0.9238 - val_loss: 13.0066 - val_acc: 0.1778\n",
      "Epoch 31/50\n",
      "420/420 [==============================] - 0s 181us/step - loss: 0.1914 - acc: 0.9214 - val_loss: 13.0169 - val_acc: 0.1778\n",
      "Epoch 32/50\n",
      "420/420 [==============================] - 0s 188us/step - loss: 0.1907 - acc: 0.9262 - val_loss: 13.0156 - val_acc: 0.1778\n",
      "Epoch 33/50\n",
      "420/420 [==============================] - 0s 169us/step - loss: 0.1899 - acc: 0.9238 - val_loss: 13.0187 - val_acc: 0.1778\n",
      "Epoch 34/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.1889 - acc: 0.9286 - val_loss: 13.0185 - val_acc: 0.1778\n",
      "Epoch 35/50\n",
      "420/420 [==============================] - 0s 136us/step - loss: 0.1882 - acc: 0.9238 - val_loss: 13.0136 - val_acc: 0.1778\n",
      "Epoch 36/50\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.1885 - acc: 0.9286 - val_loss: 13.0109 - val_acc: 0.1778\n",
      "Epoch 37/50\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.1887 - acc: 0.9238 - val_loss: 13.0145 - val_acc: 0.1778\n",
      "Epoch 38/50\n",
      "420/420 [==============================] - 0s 157us/step - loss: 0.1871 - acc: 0.9286 - val_loss: 13.0185 - val_acc: 0.1778\n",
      "Epoch 39/50\n",
      "420/420 [==============================] - 0s 155us/step - loss: 0.1869 - acc: 0.9238 - val_loss: 13.0221 - val_acc: 0.1778\n",
      "Epoch 40/50\n",
      "420/420 [==============================] - 0s 167us/step - loss: 0.1864 - acc: 0.9238 - val_loss: 13.0216 - val_acc: 0.1778\n",
      "Epoch 41/50\n",
      "420/420 [==============================] - 0s 176us/step - loss: 0.1861 - acc: 0.9262 - val_loss: 13.0164 - val_acc: 0.1778\n",
      "Epoch 42/50\n",
      "420/420 [==============================] - 0s 176us/step - loss: 0.1841 - acc: 0.9238 - val_loss: 13.0072 - val_acc: 0.1778\n",
      "Epoch 43/50\n",
      "420/420 [==============================] - 0s 160us/step - loss: 0.1842 - acc: 0.9262 - val_loss: 13.0160 - val_acc: 0.1778\n",
      "Epoch 44/50\n",
      "420/420 [==============================] - 0s 152us/step - loss: 0.1853 - acc: 0.9262 - val_loss: 13.0183 - val_acc: 0.1778\n",
      "Epoch 45/50\n",
      "420/420 [==============================] - 0s 122us/step - loss: 0.1839 - acc: 0.9310 - val_loss: 13.0150 - val_acc: 0.1778\n",
      "Epoch 46/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.1824 - acc: 0.9238 - val_loss: 13.0130 - val_acc: 0.1778\n",
      "Epoch 47/50\n",
      "420/420 [==============================] - 0s 176us/step - loss: 0.1821 - acc: 0.9262 - val_loss: 13.0163 - val_acc: 0.1778\n",
      "Epoch 48/50\n",
      "420/420 [==============================] - 0s 143us/step - loss: 0.1813 - acc: 0.9238 - val_loss: 13.0082 - val_acc: 0.1778\n",
      "Epoch 49/50\n",
      "420/420 [==============================] - 0s 145us/step - loss: 0.1807 - acc: 0.9357 - val_loss: 13.0083 - val_acc: 0.1778\n",
      "Epoch 50/50\n",
      "420/420 [==============================] - 0s 138us/step - loss: 0.1813 - acc: 0.9262 - val_loss: 13.0099 - val_acc: 0.1778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3d2a2ff28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(data, label, validation_split=0.3, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, tr_label, te_data, te_label = read3.readData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = keras.utils.to_categorical(tr_label, num_classes=10)\n",
    "test_label = keras.utils.to_categorical(te_label, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential([\n",
    "    Dense(32, input_shape=(27,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "model5.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 415 samples, validate on 175 samples\n",
      "Epoch 1/100\n",
      "415/415 [==============================] - 0s 159us/step - loss: 1.2250 - acc: 0.8940 - val_loss: 1.7171 - val_acc: 0.7943\n",
      "Epoch 2/100\n",
      "415/415 [==============================] - 0s 137us/step - loss: 1.2271 - acc: 0.8940 - val_loss: 1.6609 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "415/415 [==============================] - 0s 137us/step - loss: 1.2228 - acc: 0.8964 - val_loss: 1.6985 - val_acc: 0.7943\n",
      "Epoch 4/100\n",
      "415/415 [==============================] - 0s 137us/step - loss: 1.2258 - acc: 0.8916 - val_loss: 1.6662 - val_acc: 0.7829\n",
      "Epoch 5/100\n",
      "415/415 [==============================] - 0s 162us/step - loss: 1.2150 - acc: 0.9012 - val_loss: 1.7243 - val_acc: 0.7829\n",
      "Epoch 6/100\n",
      "415/415 [==============================] - 0s 145us/step - loss: 1.2224 - acc: 0.8964 - val_loss: 1.7012 - val_acc: 0.7943\n",
      "Epoch 7/100\n",
      "415/415 [==============================] - 0s 121us/step - loss: 1.2206 - acc: 0.8867 - val_loss: 1.6713 - val_acc: 0.7943\n",
      "Epoch 8/100\n",
      "415/415 [==============================] - 0s 166us/step - loss: 1.2134 - acc: 0.9036 - val_loss: 1.7521 - val_acc: 0.7829\n",
      "Epoch 9/100\n",
      "415/415 [==============================] - 0s 128us/step - loss: 1.2155 - acc: 0.8964 - val_loss: 1.7339 - val_acc: 0.7943\n",
      "Epoch 10/100\n",
      "415/415 [==============================] - 0s 137us/step - loss: 1.2199 - acc: 0.8916 - val_loss: 1.7030 - val_acc: 0.8057\n",
      "Epoch 11/100\n",
      "415/415 [==============================] - 0s 121us/step - loss: 1.2195 - acc: 0.8940 - val_loss: 1.6913 - val_acc: 0.8057\n",
      "Epoch 12/100\n",
      "415/415 [==============================] - 0s 174us/step - loss: 1.2080 - acc: 0.9036 - val_loss: 1.7189 - val_acc: 0.7886\n",
      "Epoch 13/100\n",
      "415/415 [==============================] - 0s 149us/step - loss: 1.2126 - acc: 0.8988 - val_loss: 1.7454 - val_acc: 0.7886\n",
      "Epoch 14/100\n",
      "415/415 [==============================] - 0s 183us/step - loss: 1.2102 - acc: 0.9012 - val_loss: 1.7894 - val_acc: 0.7886\n",
      "Epoch 15/100\n",
      "415/415 [==============================] - 0s 159us/step - loss: 1.2090 - acc: 0.9012 - val_loss: 1.6971 - val_acc: 0.7886\n",
      "Epoch 16/100\n",
      "415/415 [==============================] - 0s 171us/step - loss: 1.2022 - acc: 0.9084 - val_loss: 1.7414 - val_acc: 0.7657\n",
      "Epoch 17/100\n",
      "415/415 [==============================] - 0s 174us/step - loss: 1.2103 - acc: 0.9036 - val_loss: 1.7304 - val_acc: 0.7943\n",
      "Epoch 18/100\n",
      "415/415 [==============================] - 0s 176us/step - loss: 1.2109 - acc: 0.8964 - val_loss: 1.7187 - val_acc: 0.7943\n",
      "Epoch 19/100\n",
      "415/415 [==============================] - 0s 198us/step - loss: 1.2070 - acc: 0.9108 - val_loss: 1.7178 - val_acc: 0.7771\n",
      "Epoch 20/100\n",
      "415/415 [==============================] - 0s 186us/step - loss: 1.2102 - acc: 0.9012 - val_loss: 1.7346 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "415/415 [==============================] - 0s 186us/step - loss: 1.2074 - acc: 0.9060 - val_loss: 1.8126 - val_acc: 0.7886\n",
      "Epoch 22/100\n",
      "415/415 [==============================] - 0s 188us/step - loss: 1.2053 - acc: 0.9036 - val_loss: 1.7246 - val_acc: 0.7886\n",
      "Epoch 23/100\n",
      "415/415 [==============================] - 0s 157us/step - loss: 1.1971 - acc: 0.9036 - val_loss: 1.7318 - val_acc: 0.7886\n",
      "Epoch 24/100\n",
      "415/415 [==============================] - 0s 171us/step - loss: 1.1997 - acc: 0.9084 - val_loss: 1.7191 - val_acc: 0.7943\n",
      "Epoch 25/100\n",
      "415/415 [==============================] - 0s 183us/step - loss: 1.2022 - acc: 0.9060 - val_loss: 1.7085 - val_acc: 0.7886\n",
      "Epoch 26/100\n",
      "415/415 [==============================] - 0s 188us/step - loss: 1.2004 - acc: 0.9108 - val_loss: 1.7631 - val_acc: 0.7943\n",
      "Epoch 27/100\n",
      "415/415 [==============================] - 0s 188us/step - loss: 1.1944 - acc: 0.9108 - val_loss: 1.6866 - val_acc: 0.7886\n",
      "Epoch 28/100\n",
      "415/415 [==============================] - 0s 195us/step - loss: 1.1935 - acc: 0.9108 - val_loss: 1.7648 - val_acc: 0.7943\n",
      "Epoch 29/100\n",
      "415/415 [==============================] - 0s 174us/step - loss: 1.1993 - acc: 0.9133 - val_loss: 1.7302 - val_acc: 0.7886\n",
      "Epoch 30/100\n",
      "415/415 [==============================] - 0s 188us/step - loss: 1.1940 - acc: 0.9108 - val_loss: 1.7967 - val_acc: 0.7829\n",
      "Epoch 31/100\n",
      "415/415 [==============================] - 0s 171us/step - loss: 1.1891 - acc: 0.9133 - val_loss: 1.7406 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "415/415 [==============================] - 0s 135us/step - loss: 1.1936 - acc: 0.9157 - val_loss: 1.7199 - val_acc: 0.7886\n",
      "Epoch 33/100\n",
      "415/415 [==============================] - 0s 142us/step - loss: 1.1883 - acc: 0.9084 - val_loss: 1.7294 - val_acc: 0.7943\n",
      "Epoch 34/100\n",
      "415/415 [==============================] - 0s 176us/step - loss: 1.1868 - acc: 0.9108 - val_loss: 1.7578 - val_acc: 0.7943\n",
      "Epoch 35/100\n",
      "415/415 [==============================] - 0s 205us/step - loss: 1.1899 - acc: 0.9157 - val_loss: 1.8006 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "415/415 [==============================] - 0s 171us/step - loss: 1.1845 - acc: 0.9181 - val_loss: 1.7999 - val_acc: 0.7829\n",
      "Epoch 37/100\n",
      "415/415 [==============================] - 0s 162us/step - loss: 1.1882 - acc: 0.9133 - val_loss: 1.7562 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "415/415 [==============================] - 0s 183us/step - loss: 1.1891 - acc: 0.9181 - val_loss: 1.7504 - val_acc: 0.7771\n",
      "Epoch 39/100\n",
      "415/415 [==============================] - 0s 164us/step - loss: 1.1821 - acc: 0.9157 - val_loss: 1.8454 - val_acc: 0.7886\n",
      "Epoch 40/100\n",
      "415/415 [==============================] - 0s 159us/step - loss: 1.1896 - acc: 0.9181 - val_loss: 1.7345 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "415/415 [==============================] - 0s 162us/step - loss: 1.1787 - acc: 0.9205 - val_loss: 1.7879 - val_acc: 0.7886\n",
      "Epoch 42/100\n",
      "415/415 [==============================] - 0s 157us/step - loss: 1.1832 - acc: 0.9181 - val_loss: 1.7626 - val_acc: 0.7886\n",
      "Epoch 43/100\n",
      "415/415 [==============================] - 0s 186us/step - loss: 1.1845 - acc: 0.9157 - val_loss: 1.7689 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "415/415 [==============================] - 0s 169us/step - loss: 1.1819 - acc: 0.9133 - val_loss: 1.7703 - val_acc: 0.7943\n",
      "Epoch 45/100\n",
      "415/415 [==============================] - 0s 154us/step - loss: 1.1750 - acc: 0.9205 - val_loss: 1.8312 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "415/415 [==============================] - 0s 171us/step - loss: 1.1847 - acc: 0.9157 - val_loss: 1.7968 - val_acc: 0.8057\n",
      "Epoch 47/100\n",
      "415/415 [==============================] - 0s 166us/step - loss: 1.1761 - acc: 0.9181 - val_loss: 1.7577 - val_acc: 0.7943\n",
      "Epoch 48/100\n",
      "415/415 [==============================] - 0s 164us/step - loss: 1.1751 - acc: 0.9157 - val_loss: 1.8227 - val_acc: 0.8000\n",
      "Epoch 49/100\n",
      "415/415 [==============================] - 0s 178us/step - loss: 1.1751 - acc: 0.9205 - val_loss: 1.8135 - val_acc: 0.7943\n",
      "Epoch 50/100\n",
      "415/415 [==============================] - 0s 133us/step - loss: 1.1819 - acc: 0.9108 - val_loss: 1.7886 - val_acc: 0.7886\n",
      "Epoch 51/100\n",
      "415/415 [==============================] - 0s 154us/step - loss: 1.1721 - acc: 0.9181 - val_loss: 1.8198 - val_acc: 0.7943\n",
      "Epoch 52/100\n",
      "415/415 [==============================] - 0s 159us/step - loss: 1.1801 - acc: 0.9157 - val_loss: 1.8405 - val_acc: 0.7943\n",
      "Epoch 53/100\n",
      "415/415 [==============================] - 0s 164us/step - loss: 1.1729 - acc: 0.9205 - val_loss: 1.7919 - val_acc: 0.7886\n",
      "Epoch 54/100\n",
      "415/415 [==============================] - 0s 162us/step - loss: 1.1674 - acc: 0.9229 - val_loss: 1.8956 - val_acc: 0.7714\n",
      "Epoch 55/100\n",
      "415/415 [==============================] - 0s 166us/step - loss: 1.1770 - acc: 0.9181 - val_loss: 1.8402 - val_acc: 0.7943\n",
      "Epoch 56/100\n",
      "415/415 [==============================] - 0s 154us/step - loss: 1.1724 - acc: 0.9181 - val_loss: 1.8249 - val_acc: 0.7886\n",
      "Epoch 57/100\n",
      "415/415 [==============================] - 0s 181us/step - loss: 1.1682 - acc: 0.9229 - val_loss: 1.8202 - val_acc: 0.7943\n",
      "Epoch 58/100\n",
      "415/415 [==============================] - 0s 176us/step - loss: 1.1704 - acc: 0.9205 - val_loss: 1.8554 - val_acc: 0.7886\n",
      "Epoch 59/100\n",
      "415/415 [==============================] - 0s 188us/step - loss: 1.1668 - acc: 0.9205 - val_loss: 1.8728 - val_acc: 0.7829\n",
      "Epoch 60/100\n",
      "415/415 [==============================] - 0s 166us/step - loss: 1.1738 - acc: 0.9205 - val_loss: 1.8447 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "415/415 [==============================] - 0s 183us/step - loss: 1.1629 - acc: 0.9253 - val_loss: 1.9339 - val_acc: 0.7886\n",
      "Epoch 62/100\n",
      "415/415 [==============================] - 0s 169us/step - loss: 1.1719 - acc: 0.9181 - val_loss: 1.8444 - val_acc: 0.7886\n",
      "Epoch 63/100\n",
      "415/415 [==============================] - 0s 149us/step - loss: 1.1642 - acc: 0.9253 - val_loss: 1.9108 - val_acc: 0.7829\n",
      "Epoch 64/100\n",
      "415/415 [==============================] - 0s 135us/step - loss: 1.1660 - acc: 0.9205 - val_loss: 1.9181 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "415/415 [==============================] - 0s 133us/step - loss: 1.1650 - acc: 0.9205 - val_loss: 1.8942 - val_acc: 0.8000\n",
      "Epoch 66/100\n",
      "415/415 [==============================] - 0s 133us/step - loss: 1.1668 - acc: 0.9253 - val_loss: 1.8847 - val_acc: 0.7943\n",
      "Epoch 67/100\n",
      "415/415 [==============================] - 0s 140us/step - loss: 1.1635 - acc: 0.9253 - val_loss: 1.8601 - val_acc: 0.7886\n",
      "Epoch 68/100\n",
      "415/415 [==============================] - 0s 137us/step - loss: 1.1629 - acc: 0.9229 - val_loss: 1.8582 - val_acc: 0.7943\n",
      "Epoch 69/100\n",
      "415/415 [==============================] - 0s 181us/step - loss: 1.1649 - acc: 0.9229 - val_loss: 1.8361 - val_acc: 0.7943\n",
      "Epoch 70/100\n",
      "415/415 [==============================] - 0s 193us/step - loss: 1.1602 - acc: 0.9229 - val_loss: 1.8800 - val_acc: 0.8000\n",
      "Epoch 71/100\n",
      "415/415 [==============================] - 0s 186us/step - loss: 1.1626 - acc: 0.9229 - val_loss: 1.8930 - val_acc: 0.7943\n",
      "Epoch 72/100\n",
      "415/415 [==============================] - 0s 176us/step - loss: 1.1601 - acc: 0.9277 - val_loss: 1.8723 - val_acc: 0.8000\n",
      "Epoch 73/100\n",
      "415/415 [==============================] - 0s 176us/step - loss: 1.1607 - acc: 0.9229 - val_loss: 1.8891 - val_acc: 0.7943\n",
      "Epoch 74/100\n",
      "415/415 [==============================] - 0s 140us/step - loss: 1.1575 - acc: 0.9229 - val_loss: 1.9615 - val_acc: 0.7943\n",
      "Epoch 75/100\n",
      "415/415 [==============================] - 0s 159us/step - loss: 1.1598 - acc: 0.9229 - val_loss: 1.9347 - val_acc: 0.7886\n",
      "Epoch 76/100\n",
      "415/415 [==============================] - 0s 137us/step - loss: 1.1568 - acc: 0.9301 - val_loss: 1.9658 - val_acc: 0.7886\n",
      "Epoch 77/100\n",
      "415/415 [==============================] - 0s 200us/step - loss: 1.1586 - acc: 0.9229 - val_loss: 1.9214 - val_acc: 0.7943\n",
      "Epoch 78/100\n",
      "415/415 [==============================] - 0s 188us/step - loss: 1.1568 - acc: 0.9277 - val_loss: 1.9134 - val_acc: 0.7943\n",
      "Epoch 79/100\n",
      "415/415 [==============================] - 0s 183us/step - loss: 1.1546 - acc: 0.9253 - val_loss: 1.9251 - val_acc: 0.7943\n",
      "Epoch 80/100\n",
      "415/415 [==============================] - 0s 171us/step - loss: 1.1639 - acc: 0.9229 - val_loss: 1.9081 - val_acc: 0.7943\n",
      "Epoch 81/100\n",
      "415/415 [==============================] - 0s 174us/step - loss: 1.1553 - acc: 0.9253 - val_loss: 1.9477 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "415/415 [==============================] - 0s 183us/step - loss: 1.1529 - acc: 0.9277 - val_loss: 1.9398 - val_acc: 0.7886\n",
      "Epoch 83/100\n",
      "415/415 [==============================] - 0s 164us/step - loss: 1.1563 - acc: 0.9253 - val_loss: 1.9980 - val_acc: 0.7829\n",
      "Epoch 84/100\n",
      "415/415 [==============================] - 0s 174us/step - loss: 1.1527 - acc: 0.9277 - val_loss: 2.0102 - val_acc: 0.7829\n",
      "Epoch 85/100\n",
      "415/415 [==============================] - 0s 200us/step - loss: 1.1569 - acc: 0.9253 - val_loss: 1.9060 - val_acc: 0.7886\n",
      "Epoch 86/100\n",
      "415/415 [==============================] - 0s 188us/step - loss: 1.1516 - acc: 0.9301 - val_loss: 1.9603 - val_acc: 0.7943\n",
      "Epoch 87/100\n",
      "415/415 [==============================] - 0s 186us/step - loss: 1.1533 - acc: 0.9253 - val_loss: 1.9621 - val_acc: 0.8000\n",
      "Epoch 88/100\n",
      "415/415 [==============================] - 0s 166us/step - loss: 1.1510 - acc: 0.9253 - val_loss: 1.9430 - val_acc: 0.7943\n",
      "Epoch 89/100\n",
      "415/415 [==============================] - 0s 178us/step - loss: 1.1485 - acc: 0.9301 - val_loss: 1.9883 - val_acc: 0.8000\n",
      "Epoch 90/100\n",
      "415/415 [==============================] - 0s 169us/step - loss: 1.1507 - acc: 0.9253 - val_loss: 1.9937 - val_acc: 0.7886\n",
      "Epoch 91/100\n",
      "415/415 [==============================] - 0s 181us/step - loss: 1.1501 - acc: 0.9277 - val_loss: 2.0860 - val_acc: 0.7829\n",
      "Epoch 92/100\n",
      "415/415 [==============================] - 0s 183us/step - loss: 1.1510 - acc: 0.9253 - val_loss: 2.0315 - val_acc: 0.7943\n",
      "Epoch 93/100\n",
      "415/415 [==============================] - 0s 178us/step - loss: 1.1522 - acc: 0.9253 - val_loss: 1.9654 - val_acc: 0.7886\n",
      "Epoch 94/100\n",
      "415/415 [==============================] - 0s 181us/step - loss: 1.1478 - acc: 0.9253 - val_loss: 2.0195 - val_acc: 0.7829\n",
      "Epoch 95/100\n",
      "415/415 [==============================] - 0s 195us/step - loss: 1.1522 - acc: 0.9253 - val_loss: 1.9788 - val_acc: 0.7886\n",
      "Epoch 96/100\n",
      "415/415 [==============================] - 0s 210us/step - loss: 1.1471 - acc: 0.9301 - val_loss: 2.0379 - val_acc: 0.7829\n",
      "Epoch 97/100\n",
      "415/415 [==============================] - 0s 212us/step - loss: 1.1497 - acc: 0.9277 - val_loss: 2.0591 - val_acc: 0.7829\n",
      "Epoch 98/100\n",
      "415/415 [==============================] - 0s 203us/step - loss: 1.1464 - acc: 0.9301 - val_loss: 2.0605 - val_acc: 0.7943\n",
      "Epoch 99/100\n",
      "415/415 [==============================] - 0s 188us/step - loss: 1.1497 - acc: 0.9229 - val_loss: 2.0415 - val_acc: 0.7943\n",
      "Epoch 100/100\n",
      "415/415 [==============================] - 0s 188us/step - loss: 1.1450 - acc: 0.9301 - val_loss: 2.0491 - val_acc: 0.7886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3d429df98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(tr_data, train_label, epochs=100,validation_data=(te_data,test_label), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 401 samples, validate on 199 samples\n",
      "Epoch 1/100\n",
      "401/401 [==============================] - 0s 765us/step - loss: 2.1355 - acc: 0.3791 - val_loss: 2.5289 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "401/401 [==============================] - 0s 138us/step - loss: 1.8808 - acc: 0.6309 - val_loss: 2.6994 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "401/401 [==============================] - 0s 128us/step - loss: 1.6249 - acc: 0.6334 - val_loss: 2.9172 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "401/401 [==============================] - 0s 142us/step - loss: 1.3969 - acc: 0.6584 - val_loss: 3.2215 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "401/401 [==============================] - 0s 145us/step - loss: 1.2108 - acc: 0.6484 - val_loss: 3.5659 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "401/401 [==============================] - 0s 145us/step - loss: 1.0951 - acc: 0.6434 - val_loss: 3.9074 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "401/401 [==============================] - 0s 150us/step - loss: 1.0182 - acc: 0.6683 - val_loss: 4.2462 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "401/401 [==============================] - 0s 182us/step - loss: 0.9644 - acc: 0.6484 - val_loss: 4.5496 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.9198 - acc: 0.6559 - val_loss: 4.8295 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "401/401 [==============================] - 0s 147us/step - loss: 0.8796 - acc: 0.6833 - val_loss: 5.0828 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.8442 - acc: 0.6933 - val_loss: 5.3593 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "401/401 [==============================] - 0s 170us/step - loss: 0.8113 - acc: 0.7007 - val_loss: 5.6685 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "401/401 [==============================] - 0s 150us/step - loss: 0.7788 - acc: 0.7132 - val_loss: 5.9853 - val_acc: 0.0050\n",
      "Epoch 14/100\n",
      "401/401 [==============================] - 0s 187us/step - loss: 0.7499 - acc: 0.7332 - val_loss: 6.2482 - val_acc: 0.0050\n",
      "Epoch 15/100\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.7237 - acc: 0.7406 - val_loss: 6.5545 - val_acc: 0.0050\n",
      "Epoch 16/100\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.6984 - acc: 0.7481 - val_loss: 6.8322 - val_acc: 0.0201\n",
      "Epoch 17/100\n",
      "401/401 [==============================] - 0s 162us/step - loss: 0.6761 - acc: 0.7581 - val_loss: 7.0829 - val_acc: 0.0352\n",
      "Epoch 18/100\n",
      "401/401 [==============================] - 0s 152us/step - loss: 0.6561 - acc: 0.7681 - val_loss: 7.3837 - val_acc: 0.0402\n",
      "Epoch 19/100\n",
      "401/401 [==============================] - 0s 172us/step - loss: 0.6387 - acc: 0.7756 - val_loss: 7.6322 - val_acc: 0.0402\n",
      "Epoch 20/100\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.6208 - acc: 0.7880 - val_loss: 7.8433 - val_acc: 0.0704\n",
      "Epoch 21/100\n",
      "401/401 [==============================] - 0s 125us/step - loss: 0.6029 - acc: 0.7880 - val_loss: 8.0940 - val_acc: 0.0804\n",
      "Epoch 22/100\n",
      "401/401 [==============================] - 0s 170us/step - loss: 0.5871 - acc: 0.8055 - val_loss: 8.3173 - val_acc: 0.0804\n",
      "Epoch 23/100\n",
      "401/401 [==============================] - 0s 205us/step - loss: 0.5723 - acc: 0.8080 - val_loss: 8.5522 - val_acc: 0.0854\n",
      "Epoch 24/100\n",
      "401/401 [==============================] - 0s 177us/step - loss: 0.5586 - acc: 0.8080 - val_loss: 8.7505 - val_acc: 0.1910\n",
      "Epoch 25/100\n",
      "401/401 [==============================] - 0s 150us/step - loss: 0.5462 - acc: 0.8279 - val_loss: 8.9608 - val_acc: 0.1910\n",
      "Epoch 26/100\n",
      "401/401 [==============================] - 0s 170us/step - loss: 0.5327 - acc: 0.8429 - val_loss: 9.1914 - val_acc: 0.1960\n",
      "Epoch 27/100\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.5218 - acc: 0.8479 - val_loss: 9.3944 - val_acc: 0.2010\n",
      "Epoch 28/100\n",
      "401/401 [==============================] - 0s 167us/step - loss: 0.5104 - acc: 0.8379 - val_loss: 9.5555 - val_acc: 0.2060\n",
      "Epoch 29/100\n",
      "401/401 [==============================] - 0s 172us/step - loss: 0.5005 - acc: 0.8479 - val_loss: 9.7457 - val_acc: 0.2111\n",
      "Epoch 30/100\n",
      "401/401 [==============================] - 0s 182us/step - loss: 0.4912 - acc: 0.8504 - val_loss: 9.9035 - val_acc: 0.2060\n",
      "Epoch 31/100\n",
      "401/401 [==============================] - 0s 162us/step - loss: 0.4811 - acc: 0.8579 - val_loss: 10.0923 - val_acc: 0.2111\n",
      "Epoch 32/100\n",
      "401/401 [==============================] - 0s 170us/step - loss: 0.4724 - acc: 0.8579 - val_loss: 10.2474 - val_acc: 0.2111\n",
      "Epoch 33/100\n",
      "401/401 [==============================] - 0s 155us/step - loss: 0.4643 - acc: 0.8529 - val_loss: 10.3814 - val_acc: 0.2111\n",
      "Epoch 34/100\n",
      "401/401 [==============================] - 0s 182us/step - loss: 0.4558 - acc: 0.8628 - val_loss: 10.5190 - val_acc: 0.2111\n",
      "Epoch 35/100\n",
      "401/401 [==============================] - 0s 182us/step - loss: 0.4487 - acc: 0.8653 - val_loss: 10.6687 - val_acc: 0.2111\n",
      "Epoch 36/100\n",
      "401/401 [==============================] - 0s 190us/step - loss: 0.4429 - acc: 0.8653 - val_loss: 10.7828 - val_acc: 0.2111\n",
      "Epoch 37/100\n",
      "401/401 [==============================] - 0s 192us/step - loss: 0.4344 - acc: 0.8703 - val_loss: 10.9209 - val_acc: 0.2111\n",
      "Epoch 38/100\n",
      "401/401 [==============================] - 0s 175us/step - loss: 0.4290 - acc: 0.8728 - val_loss: 11.0256 - val_acc: 0.2111\n",
      "Epoch 39/100\n",
      "401/401 [==============================] - 0s 147us/step - loss: 0.4218 - acc: 0.8653 - val_loss: 11.1127 - val_acc: 0.2211\n",
      "Epoch 40/100\n",
      "401/401 [==============================] - 0s 172us/step - loss: 0.4153 - acc: 0.8728 - val_loss: 11.1824 - val_acc: 0.2211\n",
      "Epoch 41/100\n",
      "401/401 [==============================] - 0s 187us/step - loss: 0.4075 - acc: 0.8728 - val_loss: 11.2882 - val_acc: 0.2211\n",
      "Epoch 42/100\n",
      "401/401 [==============================] - 0s 187us/step - loss: 0.4046 - acc: 0.8728 - val_loss: 11.3425 - val_acc: 0.2211\n",
      "Epoch 43/100\n",
      "401/401 [==============================] - 0s 192us/step - loss: 0.3997 - acc: 0.8728 - val_loss: 11.3865 - val_acc: 0.2211\n",
      "Epoch 44/100\n",
      "401/401 [==============================] - 0s 182us/step - loss: 0.3926 - acc: 0.8778 - val_loss: 11.4328 - val_acc: 0.2462\n",
      "Epoch 45/100\n",
      "401/401 [==============================] - 0s 157us/step - loss: 0.3901 - acc: 0.8853 - val_loss: 11.4701 - val_acc: 0.2211\n",
      "Epoch 46/100\n",
      "401/401 [==============================] - 0s 142us/step - loss: 0.3848 - acc: 0.8728 - val_loss: 11.5025 - val_acc: 0.2513\n",
      "Epoch 47/100\n",
      "401/401 [==============================] - 0s 167us/step - loss: 0.3802 - acc: 0.8828 - val_loss: 11.5256 - val_acc: 0.2513\n",
      "Epoch 48/100\n",
      "401/401 [==============================] - 0s 162us/step - loss: 0.3757 - acc: 0.8853 - val_loss: 11.5614 - val_acc: 0.2513\n",
      "Epoch 49/100\n",
      "401/401 [==============================] - 0s 162us/step - loss: 0.3719 - acc: 0.8853 - val_loss: 11.5841 - val_acc: 0.2563\n",
      "Epoch 50/100\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.3681 - acc: 0.8878 - val_loss: 11.6074 - val_acc: 0.2563\n",
      "Epoch 51/100\n",
      "401/401 [==============================] - 0s 150us/step - loss: 0.3632 - acc: 0.8853 - val_loss: 11.6307 - val_acc: 0.2563\n",
      "Epoch 52/100\n",
      "401/401 [==============================] - 0s 157us/step - loss: 0.3602 - acc: 0.8853 - val_loss: 11.6477 - val_acc: 0.2563\n",
      "Epoch 53/100\n",
      "401/401 [==============================] - 0s 162us/step - loss: 0.3557 - acc: 0.8878 - val_loss: 11.6600 - val_acc: 0.2563\n",
      "Epoch 54/100\n",
      "401/401 [==============================] - 0s 185us/step - loss: 0.3532 - acc: 0.8828 - val_loss: 11.6740 - val_acc: 0.2563\n",
      "Epoch 55/100\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.3490 - acc: 0.8853 - val_loss: 11.6959 - val_acc: 0.2563\n",
      "Epoch 56/100\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.3444 - acc: 0.8853 - val_loss: 11.7045 - val_acc: 0.2563\n",
      "Epoch 57/100\n",
      "401/401 [==============================] - 0s 137us/step - loss: 0.3416 - acc: 0.8828 - val_loss: 11.7324 - val_acc: 0.2563\n",
      "Epoch 58/100\n",
      "401/401 [==============================] - 0s 142us/step - loss: 0.3397 - acc: 0.8853 - val_loss: 11.7501 - val_acc: 0.2563\n",
      "Epoch 59/100\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.3363 - acc: 0.8853 - val_loss: 11.7617 - val_acc: 0.2563\n",
      "Epoch 60/100\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.3336 - acc: 0.8878 - val_loss: 11.7693 - val_acc: 0.2563\n",
      "Epoch 61/100\n",
      "401/401 [==============================] - 0s 142us/step - loss: 0.3299 - acc: 0.8828 - val_loss: 11.7842 - val_acc: 0.2563\n",
      "Epoch 62/100\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.3281 - acc: 0.8828 - val_loss: 11.7988 - val_acc: 0.2563\n",
      "Epoch 63/100\n",
      "401/401 [==============================] - 0s 133us/step - loss: 0.3251 - acc: 0.8853 - val_loss: 11.8013 - val_acc: 0.2563\n",
      "Epoch 64/100\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.3206 - acc: 0.8928 - val_loss: 11.8262 - val_acc: 0.2563\n",
      "Epoch 65/100\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.3203 - acc: 0.8853 - val_loss: 11.8382 - val_acc: 0.2563\n",
      "Epoch 66/100\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.3182 - acc: 0.8853 - val_loss: 11.8417 - val_acc: 0.2563\n",
      "Epoch 67/100\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.3158 - acc: 0.8828 - val_loss: 11.8551 - val_acc: 0.2563\n",
      "Epoch 68/100\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.3134 - acc: 0.8803 - val_loss: 11.8554 - val_acc: 0.2563\n",
      "Epoch 69/100\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.3109 - acc: 0.8803 - val_loss: 11.8657 - val_acc: 0.2563\n",
      "Epoch 70/100\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.3093 - acc: 0.8853 - val_loss: 11.8725 - val_acc: 0.2563\n",
      "Epoch 71/100\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.3072 - acc: 0.8878 - val_loss: 11.8754 - val_acc: 0.2563\n",
      "Epoch 72/100\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.3049 - acc: 0.8878 - val_loss: 11.8804 - val_acc: 0.2563\n",
      "Epoch 73/100\n",
      "401/401 [==============================] - 0s 120us/step - loss: 0.3028 - acc: 0.8803 - val_loss: 11.8882 - val_acc: 0.2563\n",
      "Epoch 74/100\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.3019 - acc: 0.8778 - val_loss: 11.8947 - val_acc: 0.2563\n",
      "Epoch 75/100\n",
      "401/401 [==============================] - 0s 130us/step - loss: 0.2987 - acc: 0.8778 - val_loss: 11.9026 - val_acc: 0.2563\n",
      "Epoch 76/100\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.2977 - acc: 0.8853 - val_loss: 11.8986 - val_acc: 0.2563\n",
      "Epoch 77/100\n",
      "401/401 [==============================] - 0s 137us/step - loss: 0.2960 - acc: 0.8903 - val_loss: 11.9092 - val_acc: 0.2563\n",
      "Epoch 78/100\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.2937 - acc: 0.8803 - val_loss: 11.9127 - val_acc: 0.2563\n",
      "Epoch 79/100\n",
      "401/401 [==============================] - 0s 142us/step - loss: 0.2919 - acc: 0.8778 - val_loss: 11.9067 - val_acc: 0.2563\n",
      "Epoch 80/100\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.2908 - acc: 0.8828 - val_loss: 11.9249 - val_acc: 0.2563\n",
      "Epoch 81/100\n",
      "401/401 [==============================] - 0s 142us/step - loss: 0.2891 - acc: 0.8878 - val_loss: 11.9201 - val_acc: 0.2563\n",
      "Epoch 82/100\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.2879 - acc: 0.8828 - val_loss: 11.9236 - val_acc: 0.2563\n",
      "Epoch 83/100\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.2858 - acc: 0.8853 - val_loss: 11.9309 - val_acc: 0.2563\n",
      "Epoch 84/100\n",
      "401/401 [==============================] - 0s 147us/step - loss: 0.2851 - acc: 0.8878 - val_loss: 11.9304 - val_acc: 0.2563\n",
      "Epoch 85/100\n",
      "401/401 [==============================] - 0s 132us/step - loss: 0.2835 - acc: 0.8828 - val_loss: 11.9341 - val_acc: 0.2563\n",
      "Epoch 86/100\n",
      "401/401 [==============================] - 0s 135us/step - loss: 0.2814 - acc: 0.8828 - val_loss: 11.9375 - val_acc: 0.2563\n",
      "Epoch 87/100\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.2804 - acc: 0.8803 - val_loss: 11.9340 - val_acc: 0.2563\n",
      "Epoch 88/100\n",
      "401/401 [==============================] - 0s 140us/step - loss: 0.2783 - acc: 0.8853 - val_loss: 11.9419 - val_acc: 0.2563\n",
      "Epoch 89/100\n",
      "401/401 [==============================] - 0s 157us/step - loss: 0.2767 - acc: 0.8878 - val_loss: 11.9453 - val_acc: 0.2563\n",
      "Epoch 90/100\n",
      "401/401 [==============================] - 0s 142us/step - loss: 0.2760 - acc: 0.8828 - val_loss: 11.9447 - val_acc: 0.2563\n",
      "Epoch 91/100\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.2747 - acc: 0.8828 - val_loss: 11.9437 - val_acc: 0.2563\n",
      "Epoch 92/100\n",
      "401/401 [==============================] - 0s 137us/step - loss: 0.2733 - acc: 0.8853 - val_loss: 11.9484 - val_acc: 0.2563\n",
      "Epoch 93/100\n",
      "401/401 [==============================] - 0s 142us/step - loss: 0.2720 - acc: 0.8853 - val_loss: 11.9506 - val_acc: 0.2563\n",
      "Epoch 94/100\n",
      "401/401 [==============================] - 0s 147us/step - loss: 0.2697 - acc: 0.8853 - val_loss: 11.9500 - val_acc: 0.2563\n",
      "Epoch 95/100\n",
      "401/401 [==============================] - 0s 157us/step - loss: 0.2692 - acc: 0.8803 - val_loss: 11.9586 - val_acc: 0.2563\n",
      "Epoch 96/100\n",
      "401/401 [==============================] - 0s 152us/step - loss: 0.2678 - acc: 0.8853 - val_loss: 11.9563 - val_acc: 0.2563\n",
      "Epoch 97/100\n",
      "401/401 [==============================] - 0s 127us/step - loss: 0.2659 - acc: 0.8828 - val_loss: 11.9656 - val_acc: 0.2563\n",
      "Epoch 98/100\n",
      "401/401 [==============================] - 0s 150us/step - loss: 0.2659 - acc: 0.8853 - val_loss: 11.9689 - val_acc: 0.2563\n",
      "Epoch 99/100\n",
      "401/401 [==============================] - 0s 147us/step - loss: 0.2643 - acc: 0.8828 - val_loss: 11.9622 - val_acc: 0.2563\n",
      "Epoch 100/100\n",
      "401/401 [==============================] - 0s 145us/step - loss: 0.2626 - acc: 0.8803 - val_loss: 11.9557 - val_acc: 0.2563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3d44ffcc0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(data, label, epochs=100,validation_split=0.33, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = read.readData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process.normalization(data)\n",
    "label = keras.utils.to_categorical(label, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = numpy.array([1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = numpy.array([[1,2],[3,4],[5,6]])\n",
    "aa[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-54df169e32f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "aa[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
